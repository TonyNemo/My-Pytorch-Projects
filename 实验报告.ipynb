{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANNP-Image Classification-SYSU-2018 期末报告\n",
    "\n",
    "## 15336222 杨云翊 信息安全"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目录\n",
    "1. 比赛介绍\n",
    "2. 算法原理\n",
    "3. 实验内容及分析\n",
    "4. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.比赛介绍\n",
    "这是一个在kaggle上的图像分类任务, 是8分类任务,有21048个训练样例和4500个测试样例.\n",
    "\n",
    "图片内容是各种款式的衣服, 目测来自电商平台.\n",
    "\n",
    "#### 数据分析\n",
    "1. 经过统计,label的分布如下:\n",
    "    *  7    5523\n",
    "    * 3    3416\n",
    "    * 6    2558\n",
    "    * 5    2281\n",
    "    * 1    2066\n",
    "    * 4    1956\n",
    "    * 2    1780\n",
    "    * 0    1468\n",
    "2. 准备进行训练验证集分割\n",
    "    * train  80% val 20%\n",
    "   \n",
    "3. 分割后得到的数据集大小\n",
    "    * 原训练集 - 21048\n",
    "    * 现训练集 - 18943\n",
    "    * 用于验证的validation set - 2105"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 算法原理\n",
    "本实验用了迁移学习与\n",
    "In this tutorial we will take a deeper look at how to finetune and feature extract the torchvision models, all of which have been pretrained on the 1000-class Imagenet dataset. This tutorial will give an indepth look at how to work with several modern CNN architectures, and will build an intuition for finetuning any PyTorch model. Since each model architecture is different, there is no boilerplate finetuning code that will work in all scenarios. Rather, the researcher must look at the existing architecture and make custom adjustments for each model.\n",
    "\n",
    "In this document we will perform two types of transfer learning: finetuning and feature extraction. In finetuning, we start with a pretrained model and update all of the model’s parameters for our new task, in essence retraining the whole model. In feature extraction, we start with a pretrained model and only update the final layer weights from which we derive predictions. It is called feature extraction because we use the pretrained CNN as a fixed feature-extractor, and only change the output layer. For more technical information about transfer learning see here and here.\n",
    "\n",
    "In general both transfer learning methods follow the same few steps:\n",
    "\n",
    "Initialize the pretrained model\n",
    "Reshape the final layer(s) to have the same number of outputs as the number of classes in the new dataset\n",
    "Define for the optimization algorithm which parameters we want to update during training\n",
    "Run the training step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
